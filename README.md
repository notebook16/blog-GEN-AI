 

```md
# ü¶ô Llama-2-7B-Chat-GGML - Blog Generation AI  

This project uses **Llama-2-7B-Chat-GGML** to generate AI-powered blogs based on user input.  
The model is **7.6GB** (a compressed version, not the original) and can be downloaded from **Hugging Face**.  

---

## **üöÄ Running Locally**  
To run this project on your local machine, follow these steps:  

### **1Ô∏è‚É£ Download the Model**  
Download the **latest model file** from:  
üîó [Hugging Face: TheBloke/Llama-2-7B-Chat-GGML](https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGML/tree/main)  
- Scroll to the **bottom** to find the latest model.  
- Download the file ending in `.ggmlv3.q8_0.bin`.  

Move this file into your project directory.  

---

### **2Ô∏è‚É£ Create Virtual Environment & Install Dependencies**  
Run the following commands:  
```sh
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
```

---

### **3Ô∏è‚É£ Run the Application**  
```sh
streamlit run app.py
```
Your app will be available at **http://localhost:8501** or another port.  

---

## **üöÄ Deploying to Hugging Face**  
You can also deploy this app on **Hugging Face Spaces** using **Streamlit + GPU**.  

### **1Ô∏è‚É£ Push Code to Hugging Face**  
```sh
git init
git add .
git commit -m "Deploy Llama-2 Blog Gen AI"
git branch -M main
git remote add origin https://huggingface.co/spaces/YOUR-USERNAME/YOUR-SPACE-NAME
git push -u origin main
```

---

### **2Ô∏è‚É£ Authenticate with Access Token**  
When asked for a **username & password** during `git push`, use:  
- **Username** = Your Hugging Face username  
- **Password** = Hugging Face **Access Token** (Generate at: [Hugging Face Tokens](https://huggingface.co/settings/tokens))  

After pushing, Hugging Face will **automatically build and deploy your app**. üöÄ  

---

## **üîó Links**  
üîπ **Hugging Face Space**: https://huggingface.co/spaces/prince1612/my-blog-gen-ai 

